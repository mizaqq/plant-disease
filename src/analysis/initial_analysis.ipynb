{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from pathlib import Path\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt \n",
    "import cv2\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "transform = transforms.Compose([transforms.Resize(255),\n",
    "                                 transforms.CenterCrop(224),\n",
    "                                 transforms.ToTensor()])\n",
    "dataset = datasets.ImageFolder(Path('/home/miza/plant-disease/src/analysis/data_analysis.ipynb')\\\n",
    "    .parent.parent.parent.joinpath('data').joinpath('leaves'),transform=transform)\n",
    "    \n",
    "train_size = int(0.8 * len(dataset))\n",
    "test_size = len(dataset) - train_size\n",
    "train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True,num_workers=15)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False,num_workers=15)   \n",
    "def save_dataset():\n",
    "    train_folder = Path('/home/miza/plant-disease/src/analysis/data_analysis.ipynb')\\\n",
    "        .parent.parent.parent.joinpath('data').joinpath('train')\n",
    "    test_folder = Path('/home/miza/plant-disease/src/analysis/data_analysis.ipynb')\\\n",
    "        .parent.parent.parent.joinpath('data').joinpath('test')\n",
    "    train_folder.mkdir(parents=True, exist_ok=True)\n",
    "    test_folder.mkdir(parents=True, exist_ok=True)\n",
    "    def save_tensors(loader, folder):\n",
    "        for batch_idx, (images, labels) in tqdm(enumerate(loader),total=len(loader),desc=f'Saving {folder.name}'):\n",
    "            for i in range(images.size(0)):\n",
    "                img_tensor = images[i].cpu()\n",
    "                label_tensor = torch.tensor(labels[i].item(), device='cpu')\n",
    "                label_folder = folder / str(label_tensor.item())\n",
    "                label_folder.mkdir(parents=True, exist_ok=True)\n",
    "                torch.save(img_tensor, label_folder / f'{batch_idx * loader.batch_size + i}_image.pt')\n",
    "                torch.save(label_tensor, label_folder / f'{batch_idx * loader.batch_size + i}_label.pt')\n",
    "    save_tensors(train_loader, train_folder)\n",
    "    save_tensors(test_loader, test_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_to_memory(dataset, device):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img, label in tqdm(dataset,total=len(dataset)):\n",
    "        images.append(img.to(device))\n",
    "        labels.append(torch.tensor(label, device=device))\n",
    "    return torch.stack(images), torch.tensor(labels)\n",
    "\n",
    "# train_images, train_labels = load_dataset_to_memory(train_dataset, device)\n",
    "# test_images, test_labels = load_dataset_to_memory(test_dataset, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.nn.functional as F\n",
    "class Convolutional(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Convolutional, self).__init__()\n",
    "        self.conv1 = torch.nn.Conv2d(3,32,3,2,padding_mode='replicate')\n",
    "        self.pool1= torch.nn.MaxPool2d(2)\n",
    "        self.conv2 = torch.nn.Conv2d(32,64,3,2,padding_mode='replicate')\n",
    "        self.pool2= torch.nn.MaxPool2d(2)\n",
    "        self.conv3 = torch.nn.Conv2d(64,128,3,2,padding_mode='replicate')\n",
    "        self.pool3= torch.nn.MaxPool2d(2)\n",
    "        self.conv4 = torch.nn.Conv2d(128,256,3,2,padding_mode='replicate')     \n",
    "        self.pool4= torch.nn.MaxPool2d(2)\n",
    "        self.conv5 = torch.nn.Conv2d(256,512,3,2,padding_mode='replicate')\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(1152, 32)\n",
    "        self.fc2 = torch.nn.Linear(32, 4)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x= self.pool1(F.relu(self.conv1(x)))\n",
    "        x= self.pool2(F.relu(self.conv2(x)))\n",
    "        x= self.pool3(F.relu(self.conv3(x)))\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        x = F.softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:] \n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convolutional(\n",
      "  (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding_mode=replicate)\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding_mode=replicate)\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv3): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding_mode=replicate)\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv4): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding_mode=replicate)\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (conv5): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding_mode=replicate)\n",
      "  (fc1): Linear(in_features=1152, out_features=32, bias=True)\n",
      "  (fc2): Linear(in_features=32, out_features=4, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = Convolutional()\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 1: 0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 1/10 [00:31<04:44, 31.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 2: 1.344514504859322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 2/10 [01:04<04:21, 32.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 3: 1.2916464476208938\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 3/10 [01:43<04:07, 35.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 4: 1.1297692225167626\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 4/10 [02:31<04:01, 40.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 5: 1.0733061487737454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 5/10 [03:25<03:45, 45.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 6: 1.076765366290745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 6/10 [03:58<02:44, 41.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 7: 1.0676977061911632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 7/10 [04:34<01:58, 39.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 8: 1.0731102447760732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 8/10 [05:17<01:21, 40.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 9: 1.0729346698836277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 9/10 [06:10<00:44, 44.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running loss for epoch 10: 1.0700499015419107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [06:56<00:00, 41.60s/it]\n"
     ]
    }
   ],
   "source": [
    "model.to(device)\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
    "EPOCHS=10\n",
    "running_loss=0.0\n",
    "count = 1\n",
    "for epoch in tqdm(range(EPOCHS),total = EPOCHS):\n",
    "    print(f'Running loss for epoch {epoch + 1}: {running_loss/(count)}')\n",
    "    count = 0\n",
    "    running_loss = 0.0\n",
    "    for i, data in enumerate(train_loader):\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device) \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_fn(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        count+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on the test images: 67.60797342192691 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in test_loader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to(device), labels.to(device)  # Przenieś dane na GPU\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print(f'Accuracy on the test images: {100 * correct / total} %')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
